<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Home fokhrul</title>
  
  <meta name="author" content="Fokhrul">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
    #myimg{
      width:100%;
      max-width:100%;
      border-radius:50%;
      border: 1px solid #ddd;
  padding: 5px;
    }

    p {
      line-height: 22px;
      font-size: 15px;
    }

    ul li{
     font-size:15px;
    }
    
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <!-- <p style="text-align:center"> -->
                <!-- <name>Akshita Gupta</name> -->
                <p id="namechange" align="center">
                  <span id="a"><name>Md Fokhrul Islam</name></span><span id="b" style="font-family: 'Gugi', cursive; font-size: 40px;"> মোঃ ফখরুল ইসলাম</span>
              </p>
              <p style="text-align:justify" >
                I was a research assistant at department of Robotics and Mechatronics Engineering (DU)  working with <a href="https://scholar.google.com/citations?user=j8XhiIEAAAAJ&hl=en">Dr Sejuti Rahman</a> and <a href="https://scholar.google.com/citations?user=Pe8C-SUAAAAJ&hl=en">Dr Shafin Rahman</a>. 
                In my previous projct, I worked on several research projects dealing with deep learning, graph representation learning and reinforcement learning related topics.
                I also work on several projects which solve autometic trading, industrial automation and robotics problems.
              </p>
              <!-- <p style="text-align:justify" > 
                I was fortunate to spend a semester during my undergraduate studies at <a href="https://www.iitr.ac.in/">Indian Institute of Technology Roorkee</a>, 
                where I was supervised by <a href="https://scholar.google.co.in/citations?user=QU2O6JMAAAAJ&hl=en">Dr. Balasubramanian Raman</a>.
                Parrallel to my semester at IIT, I was selected as a outreachy intern, with <a href="https://www.mozilla.org/en-GB/">Mozilla</a> <a href="https://www.outreachy.org/alums/">(2018)</a>, where I was supervised by <a href="https://mozillians.org/en-US/u/emmairwin/">Emma Irwin</a>
              </p> -->
              <p style="text-align:center">
                <a href="mailto:fokhrul.rmedu@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com/citations?user=G01YeI0AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/fokhrul_i">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/fokhruli">Github</a> &nbsp/&nbsp
                <a href="https://fokhruli.github.io/islam_fokhrulCV.pdf">Resume/CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/fokhrul.jpeg"><img id = "myimg" alt="profile photo" src="images/fokhrul.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:4px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>What's New</heading> 
          <br>
          <tr>              
              <td><strong>[Feb 2022]</strong></td>
            <td>Our paper '<a herf="https://github.com/fokhruli/CM-seti-anlysis"> Data-augmentation for Bangla-English Code-Mixed Sentiment Analysis: Enhancing Cross Linguistic Contextual Understanding</a>' accepted at IEEE Access. </td>
            </tr>
          <tr>              
              <td><strong>[Oct 2022]</strong></td>
            <td>Our paper '<a herf="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936658"> AI-driven Stroke Rehabilitation Systems and Assessment: A Systematic Review </a>' accepted at IEEE TNSRE. </td>
            </tr>
          <tr>              
              <td><strong>[Oct 2022]</strong></td>
            <td>Our research project, <a herf="https://youtu.be/197FOcMHbhg">IHABOT</a>, placed second out of many others at <a herf="https://www.newagebd.net/article/184097/du-research-publication-fair-to-begin-oct-22"> the Dhaka University Research-Publication Fair</a>. </td>
            </tr>
          <tr>              
              <td><strong>[Aug 2022]</strong></td>
            <td>Attended and completed the <a herf= "https://www.oxfordml.school">OxML Summer School 2022</a> Health Track.  I enjoyed participating and learned so many interesting topics thoughout week.  </td>
            </tr> 
          <tr>              
              <td><strong>[Jun 2022]</strong></td>
            <td>Our work selected for poster in <a herf="https://sites.google.com/view/wicvcvpr2022/program/accepted-work?authuser=0"> CVPR workshop proceedings</a> that will present in person.  </td>
            </tr> 
          
          <tr>              
              <td><strong>[Feb 2022]</strong></td>
            <td>My first paper '<a herf="https://ieeexplore.ieee.org/document/9709340/keywords#keywords"> Graph Convolutional Networks for Assessment of Physical Rehabilitation Exercises</a>' accepted at IEEE TNSRE. </td>
            </tr>
          <tr>              
              <td><strong>[Dec 2021]</strong></td>
              <td>Completed undergraduate degree at RMEDU. <a href="https://twitter.com/fokhrul_i">Twitter</a> </td>
            </tr>
             <!-- 
             <tr>              
              <td><strong>[Jul 2021]</strong></td>
              <td>BiAM accepted at ICCV 2021. </td>
            </tr>
             <tr>              
              <td><strong>[Feb 2021]</strong></td>
              <td>Serving as a reviewer for ML Reproducibility Challenge 2020. </td>
            </tr>
             <tr>              
              <td><strong>[Jan 2021]</strong></td>
              <td>Paper out on arxiv: <a href="https://arxiv.org/pdf/2101.11606.pdf"> Generative Multi-Label Zero-Shot Learning </a></td>
            </tr>
             <tr>              
              <td><strong>[Jul 2020]</strong></td>
              <td>TF-VAEGAN accepted at ECCV’20. </td>
            </tr>
            <tr>              
              <td><strong>[Aug 2019]</strong></td>
              <td>A Large-scale Instance Segmentation Dataset for Aerial Images (iSAID) is available for <a href="https://captain-whu.github.io/iSAID/index.html"> download </a>.</td>
            </tr>
            <tr>              
              <td><strong>[Aug 2018]</strong></td>
              <td>One paper accepted at Interspeech, chime workshop 2018. </td>
            </tr>
            <tr>              
              <td><strong>[May 2018]</strong></td>
              <td>Selected as a Outreachy intern, with Mozilla. </td>
            </tr> 
              -->
        </tbody></table>
        <!-- This is a comment -->
        <h1></h1>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              My research interests lie broadly in machine learning and its applications to medical sectors. 
              I am particularly interested in the intersection of geometric deep learning, computer vision and reinforcement learning, in building powerful medical evaluation and prediction system.
              In my undergrad thesis, I worked on graph neural network and their application on skeleton data (for Exercise assessment). 
              Also, I had done some research based on Reinforcement Learning(RL) and Natural Language Processing(NLP).
            </p>
          </td>
        </tr>
      </tbody></table>
      <!--
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"> 
            <td style="vertical-align:middle">
               <div class="one">
                <img src='images/stgcn_rehab_main.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://akshitac8.github.io/BiAM">
                <papertitle>Discriminative Region-based Multi-Label Zero-Shot Learning</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/view/sanath-narayan">Sanath Narayan<sup>*</sup></a>,
              <strong>Akshita Gupta<sup>*</sup></strong>,
              <a href="https://salman-h-khan.github.io/">Salman Khan</a>,
              <a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan,</a><br>
              <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=en">Ling Shao,</a>
              <a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Mubarak Shah</a>
              <br>
          <strong>ICCV 2021 </strong>
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Narayan_Discriminative_Region-Based_Multi-Label_Zero-Shot_Learning_ICCV_2021_paper.pdf">paper</a> /
              <a href="https://github.com/akshitac8/BiAM">code</a>
                <ul>
                <li>
                  <u>Description:</u> Developed a attention module which combines both region-level and global-level contextual information.
                </li>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on NUS-WIDE, OpenImages by 6.9% and 31.9% mAP score.
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cvpr_result.png' width="140" align="right">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://akshitac8.github.io/GAN_MLZSL">
                <papertitle>Generative Multi-Label Zero-Shot Learning</papertitle>
              </a>
              <br>
              <strong>Akshita Gupta<sup>*</sup></strong>,
              <a href="https://sites.google.com/view/sanath-narayan">Sanath Narayan<sup>*</sup></a>,
              <a href="https://salman-h-khan.github.io/">Salman Khan</a>,
              <a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan,</a><br>
              <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=en">Ling Shao,</a>
              <a href="http://www.cvc.uab.es/LAMP/joost/">Joost van de Weijer</a>
              <br>
              <strong> Under Review in TPAMI </strong>  
              <br>
              <a href="https://arxiv.org/abs/2003.07833">paper</a> /
              <a href="https://github.com/akshitac8/Generative_MLZSL">code</a>
              <ul>
                <li>
                  <u>Description:</u> Developed a generative model that constructs multi-label features for (generalized) zero-shot learning.
                </li>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on NUS-WIDE, OpenImages and MS-COCO by 3.3%, 4.3% and 15.7% mAP score.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
      -->
           <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/OxML 2022, Certificate of participation_Md Islam-1.jpg' height="110" width="110" style="vertical-align:middle">
              </div>
            </td> 
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1yggaV7dB0H0oLrIsCHP-QQStmsaMmd-D/view?usp=sharing">
                <papertitle>Attended OxML Summer School 2022 Health Track</papertitle>
              </a>
              <br>
              <em>July 2022 - August 2022 </em>
              <br>
              Organizer: AI for Global Goals, CIFAR & University of Oxford's Deep Medecine Program
              <p>
                <ul>
                  <li>
                       Some of the topics that covered: statistical / probabilistic ML, representation learning, graph neural networks and geometrical deep learning, computer vision, knowledge-aware ML as well as topics related to ML in real-world settings. These topics were presented by leading researchers, including Michael Bronstein, S. M. Ali Eslami and others.
                  </li>
                  <li>
                      This year it was my second attempt to apply to the summer school. OxML 2022 received applications from 106 countries. I had joined from Bangladesh and enjoyed to meet ML researchers and engineers from around the world.
                  </li>
                </ul> 
               </p>
            </td>
          </tr>
        </tbody></table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/stgcn_rehab_main.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://fokhruli.github.io/STGCN-rehab/">
                <papertitle>Graph Convolutional Networks for Assessment of Physical Rehabilitation Exercises </papertitle>
              </a>
              <br>
              <a href="">Swakshar Deb<sup>*</sup></a>,
              <strong>Md Fokhrul Islam<sup>*</sup></strong>,
              <a href="https://scholar.google.com/citations?user=Pe8C-SUAAAAJ&hl=en">Shafin Rahman</a>,
              <a href="https://scholar.google.com/citations?user=j8XhiIEAAAAJ&hl=en">Sejuti Rahman</a>
              <br>
              <strong>IEEE TNSRE </strong>
              <br>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9709340">paper</a> /
              <a href="https://github.com/fokhruli/STGCN-rehab">code</a>
              <ul>
                <li>
                  <u>Description:</u>  Developed STGCN model with LSTM to extract rich spatio-temporal features and attend to different body-joints based on their role in the given exercise.
                </li>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on KIMORE and UI-PRMD by significant margin. Also handle varying length video and make guidence based on role of body joints.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
         <!--
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://akshitac8.github.io/tfvaegan/">
                <papertitle>Latent Embedding Feedback and Discriminative Features for Zero-Shot Classification</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/view/sanath-narayan">Sanath Narayan<sup>*</sup></a>,
              <strong>Akshita Gupta<sup>*</sup></strong>,
              <a href="https://salman-h-khan.github.io/">Salman Khan</a>,
              <a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan,</a><br>
              <a href="https://www.ceessnoek.info/">Cees G. M. Snoek,</a>
              <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=en">Ling Shao,</a>
              <br>
              <strong>ECCV 2020 </strong>
              <br>
              <a href="https://arxiv.org/abs/2003.07833">paper</a> /
              <a href="https://github.com/akshitac8/tfvaegan">code</a>
              <ul>
                <li>
                  <u>Description:</u> Developed a generative feature synthesizing framework for zero-shot learning.
                </li>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on CUB, FLO, SUN, and AWA by 4.6%, 7.1%, 1.7%, and 3.1% harmonic mean by enforcing semantic consistency at all stages of zero-shot learning.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        

       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/isaid.png' width="140" align="right">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://captain-whu.github.io/iSAID/">
                <papertitle>iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.es/citations?user=WNGPkVQAAAAJ&hl=en">Syed Waqas Zamir,</a>
              <a href="https://adityac8.github.io/">Aditya Arora,</a>
              <strong>Akshita Gupta</strong>,
               <a href="https://salman-h-khan.github.io/">Salman Khan,</a>
               <a href="https://scholar.google.ae/citations?user=qd8Blw0AAAAJ&hl=en">Guolei Sun,</a>
               <a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan,</a>
               <a href="https://scholar.google.com/citations?user=vD-ezyQAAAAJ&hl=en">Fan Zhu,</a>
               <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=en">Ling Shao,</a>
               <a href="http://www.captain-whu.com/xia_En.html">Gui-Song Xia,</a>
               <a href="https://scholar.google.com/citations?user=UeltiQ4AAAAJ&hl=en">Xiang Bai</a>
              <br>
              <strong>CVPR Workshop 2019 <font color="red">(Oral Presentation)</font></strong>
              <br>
              <a href="https://github.com/CAPTAIN-WHU/iSAID_Devkit">code</a> /
              <a href="https://captain-whu.github.io/iSAID/index.html">dataset</a> 
              <ul>
                <li>
                  <u>Description:</u> Improved state of the art object detector (Mask-RCNN and PANet) for aerial imagery.
                </li>
                <li>
                  <u>Outcome:</u> Proposed a large scale instance segmentation and object detection dataset (iSAID) with benchmarking on mask-RCNN and PANet.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/interspeech.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1811.00936">
                <papertitle>Acoustic features fusion using attentive multi-channel deep architecture</papertitle>
              </a>
              <br>
               <a href="http://deeplearn-ai.com/about-3/?i=1">Gaurav Bhatt,</a>
              <strong>Akshita Gupta</strong>,
               <a href="https://adityac8.github.io/">Aditya Arora,</a>
               <a href="http://bala.cs.faculty.iitr.ac.in/">Balasubramanian Raman</a>
              <br>
              <strong>Interspeech Workshop 2018 </strong>
              <br>
              <a href="https://github.com/DeepLearn-lab/Acoustic-Feature-Fusion_Chime18">code</a>
              <ul>
                <li>
                  <u>Description:</u> Developed an attention based framework for acoustic scene recognition and audio tagging.
                </li>
                <li>
                  <u>Outcome:</u> Improved the equal error rate by atleast 3% over the Dcase challenge results.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
         -->
        <!--
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Experience</heading>
            </td>
          </tr>
        </table>
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/bayant_logo.png' width="150" style="background-color:black;padding:10px;vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Data Scientist, Bayanat </papertitle>
              <br>
              <em>January, 2022 - present</em>
              <br>
              Supervisors: Dr Meng Wang, Dr Fan Zhu
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/logo_IIAI.png' width="150" style="background-color:black;padding:10px;vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Research Engineer, Inception Institute of Artificial Intelligence </papertitle>
              <br>
              <em>Dec 2018 - present</em>
              <br>
              Supervisors: Dr Sanath Narayan, Dr Salman Khan, Dr Fahad Shahbaz khan
              <p>
                <ul>
                  <li>Developing deep learning algorithms for low- (Few- and zero-) shot detection and classification, 
                  generative adversarial models and open-world object detection problems.</li>
                  <li> Developed rock & seismic layer classification system.</li>
                  <li>Worked on satellite-imagery object detection and object counting system.</li>
                </ul>
                </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/mozilla.jpg' width="160" style="vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Research & Development Intern, Mozilla, Outreachy</papertitle>
              <br>
              <em>May 2018 – Aug 2018</em>
              <br>
              Supervisor: Emma Irwin
              <p> Developed an open source analytics dashboard prototype with the metrics to evaluate diversity and inclusion across different communities.</p>
            </td>
          </tr>
        </tbody></table>
      -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/Dhaka_University_logo.svg.png' height="110" width="110" style="vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Undergraduate Researcher, University of Dhaka</papertitle>
              <br>
              <em>March 2020 – Present</em>
              <br>
              Supervisor: Dr. Sejuti Rahman
              <p>
                <ul>
                  <li>
                      Designed an autometic system based on graph convoulational network to assess and guide post-stroke rehabilitation patients. Paper accepted in IEEE TNSRE 2022.
                  </li>
                  <li>
                      Developing a framework which classify sentiment of code mixed sentiment using cross-lingual contextual understanding method in existing embedding model. 
                  </li>
                </ul> 
               </p>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/iitr.jpg' width="160" style="vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Research Intern, Indian Institute of Technology</papertitle>
              <br>
              <em>May 2017 – Jul 2017</em>
              <br>
              Supervisor: Dr R Balasubramanian
              <p>Worked on Basic Machine Learning techniques such as Support Vector Machines, K-Means Clustering and K-Nearest Neighbors and used these as a baseline for Acoustic Scene Classification.
                Setting up code environments, implemented models which were use for problems of Detection and Classification of Acoustic Scenes and Events.
                Worked on Audio Processing related challenges to minimise Equal Error rate.</p>
            </td>
          </tr>
        </tbody></table> -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
              <strong>I borrowed this website layout from <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
          </font>
            </p>
            </td>
          </tr>
          </table>
      </td>
    </tr>
  </table>
</body>

</html>
